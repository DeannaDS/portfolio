{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim \n",
    "from geopy.distance import geodesic\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Pre-Cleaning\n",
    "Before this data was pulled into Python, column labels were changed from the original Qualtrics export. Column names were standardized to camel case and shortened to useable lengths.\n",
    "\n",
    "Additionally, the data was run through the TAMU geocoding service (http://geoservices.tamu.edu/Services/Geocode/) to get latitude adn longitude for each address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the simplified final stakeholders - these are our nodes\n",
    "df = pd.read_csv('FinalStakeholders-simplified.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "For SNA/ERGM, we need to one-hot encode all the variables that are multi-valued categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the collectivism/individualism to numbers\n",
    "df['PersonalSelfDependenceScore'] = df['PersonalSelfDependence'].map({'Strongly Disagree': -2, \n",
    "                                                                      'Disagree': -1,\n",
    "                                                                     'Neutral': 0,\n",
    "                                                                     'Agree': 1,\n",
    "                                                                     'Strongly Disagree': 2})\n",
    "\n",
    "df['WorkSelfDependenceScore'] = df['WorkSelfDependence'].map({'Strongly Disagree': -2, \n",
    "                                                                      'Disagree': -1,\n",
    "                                                                     'Neutral': 0,\n",
    "                                                                     'Agree': 1,\n",
    "                                                                     'Strongly Disagree': 2})\n",
    "\n",
    "df['CollaborativeEconomicAdvantageScore'] = df['CollaborativeEconomicAdvantage'].map({'Strongly Disagree': -2, \n",
    "                                                                      'Disagree': -1,\n",
    "                                                                     'Neutral': 0,\n",
    "                                                                     'Agree': 1,\n",
    "                                                                     'Strongly Disagree': 2})\n",
    "\n",
    "df['CollaborationsNotWorthItScore'] = df['CollaborationsNotWorthIt'].map({'Strongly Disagree': -2, \n",
    "                                                                      'Disagree': -1,\n",
    "                                                                     'Neutral': 0,\n",
    "                                                                     'Agree': 1,\n",
    "                                                                     'Strongly Disagree': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mapping the collectivism/individualism to smaller categories - this didn't help\n",
    "# df['PersonalSelfDependence'] = df['PersonalSelfDependence'].map({'Strongly Disagree': 'Negative', \n",
    "#                                                                       'Disagree': 'Negative',\n",
    "#                                                                      'Neutral': 'Neutral',\n",
    "#                                                                      'Agree': 'Positive',\n",
    "#                                                                      'Strongly Disagree': 'Positive'})\n",
    "\n",
    "# df['WorkSelfDependence'] = df['WorkSelfDependence'].map({'Strongly Disagree': 'Negative', \n",
    "#                                                                       'Disagree': 'Negative',\n",
    "#                                                                      'Neutral': 'Neutral',\n",
    "#                                                                      'Agree': 'Positive',\n",
    "#                                                                      'Strongly Disagree': 'Positive'})\n",
    "\n",
    "# df['CollaborativeEconomicAdvantage'] = df['CollaborativeEconomicAdvantage'].map({'Strongly Disagree': 'Negative', \n",
    "#                                                                       'Disagree': 'Negative',\n",
    "#                                                                      'Neutral': 'Neutral',\n",
    "#                                                                      'Agree': 'Positive',\n",
    "#                                                                      'Strongly Disagree': 'Positive'})\n",
    "\n",
    "# df['CollaborationsNotWorthIt'] = df['CollaborationsNotWorthIt'].map({'Strongly Disagree': 'Negative', \n",
    "#                                                                       'Disagree': 'Negative',\n",
    "#                                                                      'Neutral': 'Neutral',\n",
    "#                                                                      'Agree': 'Positive',\n",
    "#                                                                      'Strongly Disagree': 'Positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some categories we can just use get_dummies\n",
    "\n",
    "out = pd.get_dummies(df['Location'], 'Loc')\n",
    "df = df.join(out)\n",
    "out = pd.get_dummies(df['PersonalSelfDependence'], 'PSD')\n",
    "df=df.join(out)\n",
    "out = pd.get_dummies(df['WorkSelfDependence'], 'WSD')\n",
    "df=df.join(out)\n",
    "out = pd.get_dummies(df['CollaborativeEconomicAdvantage'], 'CEA')\n",
    "df=df.join(out)\n",
    "out = pd.get_dummies(df['CollaborationsNotWorthIt'], 'CNWI')\n",
    "df=df.join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode utility\n",
    "def oneHot(df, col, indexLabel):\n",
    "    print(col)\n",
    "    cleanedCol = df.set_index(indexLabel).apply(lambda x:pd.Series(x[col]),axis=1).stack().to_frame()\n",
    "    colDummies = pd.get_dummies(cleanedCol, prefix=col, columns=[0]).groupby(level=0).sum()\n",
    "    colDummies[col+'_Combined'] = colDummies.apply(lambda x: ''.join([str(x[c]) for c in list(colDummies.columns)]), axis=1)\n",
    "    outDF = df.join(colDummies, on=indexLabel)\n",
    "    return outDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with the na's - for each of the categorical questions, add a category of unknown for those that didn't answer\n",
    "sna = df.copy().fillna({'Address': '', 'City': '', 'State': '', 'Zip': '', 'Location': 'Unknown',\n",
    "               'Roles': 'Unknown', 'RolesOther': 'None', 'SelfEmployedFlag': 'Unknown', 'BusinessName': 'Unknown',\n",
    "               'HasSecondJob': 'Unknown', 'Employer': 'Unknown',  'VendorMarkets': 'Unknown', 'ConsumerMarkets': 'Unknown',\n",
    "               'GroupAffiliations': 'Unknown', 'GroupAffiliationsOther': 'Unknown', \n",
    "                'SocialMediaFlag': 'Unknown', 'SocialMediaChoices': 'Unknown',\n",
    "               'SocialMediaOther': 'Unknown', 'HoursOnSocialMedia': 'Unknown', 'WebsiteFlag': 'Unknown', 'Website': 'Unknown', \n",
    "                'OnlineMarketingFlag': 'Unknown', 'AnswerSources': 'Unknown', 'AnswerSourcesOther': 'Unknown', \n",
    "                'NetworkOverlap': 'Unknown', 'PersonalSelfDependence': 'Unknown', 'WorkSelfDependence': 'Unknown', \n",
    "                'CollaborativeEconomicAdvantage': 'Unknown','CollaborationsNotWorthIt': 'Unknown', \n",
    "                  'PersonalSelfDependenceScore': 0, #put nonresponders in neutral\n",
    "                     'WorkSelfDependenceScore': 0,\n",
    "                      'CollaborativeEconomicAdvantageScore': 0,\n",
    "                        'CollaborationsNotWorthItScore':0,\n",
    "                'IncomePercent': 0, #people that didn't answer this are for the most part not getting any income\n",
    "                'IntrovertExtrovertScale': 5}) #put people thad didn't answer in the middle of the scale\n",
    "\n",
    "#convert the list cols to lists\n",
    "#all of these columns \n",
    "listCols = ['Roles', 'VendorMarkets', 'ConsumerMarkets', 'GroupAffiliations','SocialMediaChoices', 'AnswerSources']\n",
    "\n",
    "\n",
    "for col in listCols:\n",
    "    sna[col] = sna[col].apply(lambda x: x.split(','))\n",
    "    sna = oneHot(sna, col, 'Label')   \n",
    "    \n",
    "\n",
    "#the onehotencoding results in some terrible column names with spaces and punctuation. Let's clean that up.\n",
    "colList = list(sna.columns)\n",
    "newColNames = {}\n",
    "for col in colList:\n",
    "    newColNames[col] = re.sub(\"[- .()/']\", '', col)\n",
    "\n",
    "sna.rename(columns=newColNames, inplace=True)\n",
    "sna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = list(sna.columns)\n",
    "colList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in r we have to set a bajillion node variables, let's get the code to do it\n",
    "colList = list(sna.columns)\n",
    "for col in colList:\n",
    "    print(f\"V(allPossibleEdges)${col} <- as.character(nodeData${col}[ix])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geodistancing\n",
    "We need to create a dataframe of all nodes and determine the distance between each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sna[['Label', 'Latitude', 'Longitude']])\n",
    "\n",
    "cols = sna['Label']#[sna['ERGMFlag'] == True]\n",
    "\n",
    "geoMatrix = pd.DataFrame(0, index=cols, columns=cols)\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"CheqBaySNA\")\n",
    "\n",
    "colnames = list(geoMatrix)\n",
    "for i,j in geoMatrix.iterrows():\n",
    "    rowTuple = (float(sna['Latitude'][sna['Label'] == i]), float(sna['Longitude'][sna['Label'] == i]))\n",
    "    for c in colnames:\n",
    "        colTuple = (float(sna['Latitude'][sna['Label'] == c]), float(sna['Longitude'][sna['Label'] == c]))\n",
    "        geoMatrix[i][c] = float(geodesic(rowTuple, colTuple).miles)\n",
    "\n",
    "geoMatrix =  geoMatrix.sort_index(1).sort_index(0)\n",
    "geoMatrix.to_csv('R_distance_matrix.csv')\n",
    "\n",
    "geoMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNA Edges\n",
    "For SNA, we need a complete matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snaEdges = pd.read_csv('FromQualtricsNumericEdges.csv', header=1)\n",
    "snaEdges = (snaEdges.drop([0], axis=0)\n",
    "         .drop(['Start Date', 'End Date', 'Response Type', 'IP Address', 'Progress', \n",
    "                'Duration (in seconds)', 'Finished', 'Recorded Date', 'Response ID', 'Recipient Last Name',\n",
    "               'Recipient First Name', 'Recipient Email', 'Location Latitude', 'Location Longitude',\n",
    "               'Distribution Channel', 'User Language'], axis=1))\n",
    "\n",
    "\n",
    "colNames = list(snaEdges.columns)\n",
    "newColNames = {'External Data Reference': 'Label'}\n",
    "for c in colNames:\n",
    "    if \"Choose\" in c:\n",
    "        newColNames[c] = str.split(c, ' - ')[1]\n",
    "\n",
    "colNames = list(snaEdges.columns)\n",
    "newColNames = {'External Data Reference': 'Label'}\n",
    "for c in colNames:\n",
    "    if \"Choose\" in c:\n",
    "        newColNames[c] = str.split(c, ' - ')[1]\n",
    "\n",
    "\n",
    "        \n",
    "#rename the columns and fill unknowns\n",
    "snaEdges = snaEdges.rename(columns=newColNames)\n",
    "\n",
    "#fetch the labels\n",
    "labels = snaEdges['Label'].copy().tolist()\n",
    "\n",
    "#Fill with unknown\n",
    "snaEdges = snaEdges.fillna(1)\n",
    "\n",
    "#add the extra column - fill with Unknown - she's a weird case\n",
    "snaEdges[\"Judie Moyer (Port Wing Market)\"] = [int(1) for i in range(53)] \n",
    "\n",
    "#figure out the missing (non-respondent) rows\n",
    "missing = [c for c in snaEdges.columns if c not in labels and c != 'Label']\n",
    "\n",
    "#missing\n",
    "\n",
    "\n",
    "\n",
    "missingCols = np.full((len(missing), 10), None)\n",
    "\n",
    "missingDF = pd.DataFrame(missing, columns=['Label'])\n",
    "for c in snaEdges.columns:\n",
    "    if c != 'Label':\n",
    "        missingDF[c] = [np.nan for i in range(len(missing))]\n",
    "\n",
    "#fill Judy with unknown. She's a special case.\n",
    "snaEdges[\"Judie Moyer (Port Wing Market)\"] = [int(1) for i in range(53)]   \n",
    "\n",
    "#set the label and fill with zeros (for missing)\n",
    "snaEdges = snaEdges.append(missingDF).set_index('Label').fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "snaEdges.to_csv('R_complete_matrix.csv')\n",
    "snaEdges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the complete ties\n",
    "\n",
    "Complete ties are those for which we have both incoming and outgoing tie information. We want to review these to see what our inter-rater reliability is. In other words, how often do the 2 halves of the dyad disagree with each other about the type of relationship that they have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the zeroes to NaN and drop all incomplete cases\n",
    "snastripped = snaEdges.copy().replace(['0', 0], np.nan).dropna()\n",
    "#drop the columns for nonrespondents, giving us a square matrix\n",
    "colsToDrop = [c for c in snastripped.columns if c not in snastripped.index]\n",
    "\n",
    "#sort the rows and columns so that both are in the same order\n",
    "snastripped = snastripped.drop(columns=colsToDrop).sort_index(1).sort_index(0)\n",
    "\n",
    "snastripped.index\n",
    "\n",
    "snastripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast to numpy matrix with integer types\n",
    "npsna = snastripped.to_numpy().astype(int)\n",
    "#fill the diagonal with zero\n",
    "np.fill_diagonal(npsna, 0)\n",
    "#transpose the matrix and see what doesn't match\n",
    "print(f'The total number of relationships in which the 2 halves of the dyad disagree {np.count_nonzero(np.subtract(npsna.transpose(), npsna))}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the cleaned up column names\n",
    "colNames = list(snaEdges.columns)\n",
    "#set up 3 lists for holding our 3 columns of data\n",
    "kFrom = []\n",
    "kTo = []\n",
    "kType = []\n",
    "kWeights = []\n",
    "\n",
    "weights = {\n",
    "    'Unknown': 0,\n",
    "    'Co-exist': 1,\n",
    "    'Communicate': 2,\n",
    "    'Coordinate': 3,\n",
    "    'Collaborate': 4\n",
    "}\n",
    "\n",
    "#iterate through each row and column and get the edge combinations and their type\n",
    "for i,j in snaEdges.iterrows():\n",
    "    #for each column\n",
    "    for c in colNames:\n",
    "        #connection = ''.join(snaEdges.loc[[i],[c]].values[0])\n",
    "        #don't include self-loops, if anyone set one\n",
    "        if(i != c):\n",
    "            kFrom.append(i)\n",
    "            kTo.append(c)\n",
    "            kType.append(snaEdges.loc[[i],[c]].values[0][0])\n",
    "            #kWeights.append(weights[connection])\n",
    "\n",
    "dfKEdgeList = pd.DataFrame({'From': kFrom, 'To':kTo, 'Weight': kType})\n",
    "\n",
    "#make sure we didn't generate duplicates along the way\n",
    "dfKEdgeList = dfKEdgeList.groupby(['From', 'To', 'Weight']).count().reset_index()\n",
    "dfKEdgeList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the Distance\n",
    "Now that we have an edge list with all possible relationships, we need to add the distance between each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the distance for each pair\n",
    "def fetchDistanceIfAvailable(x):\n",
    "    try:\n",
    "         return geoMatrix[x['From']][x['To']] \n",
    "    except(ValueError,TypeError,KeyError):\n",
    "        pass\n",
    "    return np.nan    \n",
    "\n",
    "#geoMatrix['Blake Gross (Law Office of Blake Gross, Ltd.)']['Brenda Halter (Shaggy Dog Farm )']\n",
    "dfKEdgeList['Distance'] = dfKEdgeList.apply(fetchDistanceIfAvailable, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity checking that this worked.\n",
    "display(geoMatrix['Blake Gross (Law Office of Blake Gross, Ltd.)'])\n",
    "dfKEdgeList[dfKEdgeList['From'] == 'Blake Gross (Law Office of Blake Gross, Ltd.)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV\n",
    "Write these out for use in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKEdgeList.to_csv('R_edges.csv', index=False)\n",
    "sna.to_csv('R_nodes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
