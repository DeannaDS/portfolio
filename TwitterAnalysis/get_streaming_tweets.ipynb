{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving access tokens in a separate csv file that will not be included with the git push so that my credential stay local.\n",
    "keys = pd.read_csv('keys.csv')\n",
    "\n",
    "con_key = keys.con_key[0]\n",
    "con_secret = keys.con_secret[0]\n",
    "acc_token = keys.acc_token[0]\n",
    "acc_secret = keys.acc_secret[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use tweepy.OAuthHandler to create an authentication using the given key and secret\n",
    "auth = tweepy.OAuthHandler(consumer_key=con_key, consumer_secret=con_secret)\n",
    "auth.set_access_token(acc_token, acc_secret)\n",
    "\n",
    "#Connect to the Twitter API using the authentication\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We create a subclass of tweepy.StreamListener to write a line to file on_status\n",
    "class StreamListener_Writer(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, t):\n",
    "        with open(self.filename,\"a\", newline=\"\", encoding='utf-8') as tweets:\n",
    "            #pull out the hashtags\n",
    "            hashtags = [h[\"text\"] for h in t.entities[\"hashtags\"]]\n",
    "            author = t.author._json\n",
    "            authorname = author.get(\"name\", \" \")\n",
    "            authorscreenname = author.get(\"screen_name\", \" \")\n",
    "            #some of these come in as weird types (nonetype and tuple). So, only pull the string ones.\n",
    "            if isinstance(author.get(\"location\", \" \"), str) == True:\n",
    "                authorlocation = author.get(\"location\", \" \")\n",
    "            else:\n",
    "                authorlocation = \"Unknown\"\n",
    "            if isinstance(author.get(\"description\", \" \"), str) == True:\n",
    "                authordescription =  author.get(\"description\", \" \")\n",
    "            else:\n",
    "                authordescription = 'Unknown'    \n",
    "            language = author.get(\"lang\", \" \")\n",
    "            followers_count = author.get('followers_count', '0')\n",
    "            friends_count = author.get('friends_count', '0')\n",
    "            statuses_count = author.get('statuses_count', '0')\n",
    "            author_id = author.get('id_str', '')\n",
    "            text = getattr(t, 'text', '')\n",
    "            tweets.write(\"%(author_id)s|%(authorname)s|%(authorscreename)s|%(authorlocation)s|%(authordescription)s|%(followers_count)s|%(friends_count)s|%(statuses_count)s|%(language)s|%(coordinates)s|%(created_at)s|%(favorite_count)s|%(geo)s|%(text)s|%(source)s|%(retweetcount)s|%(hashtags)s\\n\" % \n",
    "                                {'author_id': author_id,\n",
    "                                 'authorname': authorname.replace('|','-').replace('\\n', ' ').replace('\\r', ' '),\n",
    "                                 'authorscreename': authorscreenname.replace('|','-').replace('\\n', ' ').replace('\\r', ' '), \n",
    "                                 'authorlocation': authorlocation.replace('|','-').replace('\\n', ' ').replace('\\r', ' '), \n",
    "                                 'authordescription': authordescription.replace('|','-').replace('\\n', ' ').replace('\\r', ' '),\n",
    "                                 'followers_count': followers_count,\n",
    "                                 'friends_count': friends_count,\n",
    "                                 'statuses_count': statuses_count,\n",
    "                                 'language': language, \n",
    "                                 'coordinates': t.coordinates, \n",
    "                                 'created_at': t.created_at, \n",
    "                                 'favorite_count': t.favorite_count, \n",
    "                                 'geo': t.geo, \n",
    "                                 'text': text.replace('|','-').replace('\\n', ' '), \n",
    "                                 'source':t.source, \n",
    "                                 'retweetcount': t.retweet_count, \n",
    "                                 'hashtags': hashtags })\n",
    "\n",
    "        \n",
    "        \n",
    "    #disconnect the stream if we receive an error message indicating we are overloading Twitter \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_data disconnects the stream\n",
    "            return False\n",
    " \n",
    "\n",
    "    #initialize the class with a tweepy stream and a file name\n",
    "    def set_up_file(self, filename):\n",
    "        self.filename = filename\n",
    "        #set up the file\n",
    "        with open(filename,\"w\", newline=\"\", encoding='utf-8') as tweets:\n",
    "            tweets.write(\"AuthorID|Author.Name|Author.Screen_Name|Author.Location|Author.Description|Followers.Count|Friends.Count|Statuses.Count|Language|Coordinates|Created_At|Favorite_count|Geo|Text|Source|retweet_count|Hashtags\\n\")\n",
    "     \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We create and authenticate an instance of our new ```StreamListener_Writer``` class\n",
    "my_stream_writer = StreamListener_Writer()\n",
    "#set up the file\n",
    "my_stream_writer.set_up_file('metoo_streaming.txt')\n",
    "my_stream = tweepy.Stream(auth = api.auth, listener=my_stream_writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, we're ready to start streaming!  We'll look for recent tweets which use the word \"data\".\n",
    "# You can pause the display of tweets by interrupting the Python kernel.\n",
    "\n",
    "my_stream.filter(track=['#metoo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Even if you pause the display of tweets, your stream is still connected to Twitter!\n",
    "# To disconnect (for example, if you want to change which words you are searching for), \n",
    "# use the disconnect() function.\n",
    "\n",
    "my_stream.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
